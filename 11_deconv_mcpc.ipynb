{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #9: Monte Carlo Predictive Coding with transposed convolution\n",
    "\n",
    "In this notebook we will see how to create and train a simple MCPC model to learn a Gaussian data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 08:47:45.795343: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.0 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "from typing import Callable, Union, Sequence\n",
    "from typing import Any, Callable, Optional, Union\n",
    "import math, os, random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import tempfile, shutil, os, subprocess, warnings\n",
    "\n",
    "\n",
    "# Core dependencies\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import optax\n",
    "import equinox as eqx\n",
    "from optax._src import base \n",
    "from optax._src import combine\n",
    "from optax._src import transform\n",
    "\n",
    "# pcax\n",
    "import pcax as px\n",
    "import pcax.predictive_coding as pxc\n",
    "import pcax.nn as pxnn\n",
    "import pcax.utils as pxu\n",
    "import pcax.functional as pxf\n",
    "from pcax.nn import Layer\n",
    "from pcax.core import RandomKeyGenerator, RKG\n",
    "\n",
    "import torch\n",
    "from pytorch_fid.fid_score_mnist import fid_mnist, save_stats_mnist\n",
    "from inception_score import get_mnist_inception_score\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvTranspose(Layer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_spatial_dims: int,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: Union[int, Sequence[int]],\n",
    "        stride: Union[int, Sequence[int]] = 1,\n",
    "        padding: Union[str, int, Sequence[int], Sequence[tuple[int, int]]] = 0,\n",
    "        output_padding: Union[int, Sequence[int]] = 0,\n",
    "        dilation: Union[int, Sequence[int]] = 1,\n",
    "        groups: int = 1,\n",
    "        use_bias: bool = True,\n",
    "        padding_mode: str = \"ZEROS\",\n",
    "        dtype=None,\n",
    "        *,\n",
    "        rkg: RandomKeyGenerator = RKG,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            eqx.nn.ConvTranspose,\n",
    "            num_spatial_dims=num_spatial_dims,\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            output_padding=output_padding,\n",
    "            dilation=dilation,\n",
    "            groups=groups,\n",
    "            use_bias=use_bias,\n",
    "            padding_mode=padding_mode,\n",
    "            key=rkg(),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "STATUS_FORWARD = \"forward\"\n",
    "\n",
    "class Model(pxc.EnergyModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        num_layers: int,\n",
    "        input_dim: tuple[int, int, int],\n",
    "        output_dim: tuple[int, int, int],\n",
    "        out_channels_per_layer: list[int] | None = None,\n",
    "        kernel_size: Union[int, Sequence[int]],\n",
    "        bottleneck_dim: int,\n",
    "        act_fn: Callable[[jax.Array], jax.Array],\n",
    "        output_act_fn: Callable[[jax.Array], jax.Array] = lambda x: x,\n",
    "        channel_last: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.act_fn = px.static(act_fn)\n",
    "        self.output_act_fn = px.static(output_act_fn)\n",
    "        self.channel_last = px.static(channel_last)\n",
    "\n",
    "        input_spatial_dim: np.array\n",
    "        output_spatial_dim: np.array\n",
    "        input_channels: int\n",
    "        output_channels: int\n",
    "        if self.channel_last.get():\n",
    "            input_spatial_dim = np.array(input_dim[:-1])\n",
    "            output_spatial_dim = np.array(output_dim[:-1])\n",
    "            input_channels = input_dim[-1]\n",
    "            output_channels = output_dim[-1]\n",
    "        else:\n",
    "            input_spatial_dim = np.array(input_dim[1:])\n",
    "            output_spatial_dim = np.array(output_dim[1:])\n",
    "            input_channels = input_dim[0]\n",
    "            output_channels = output_dim[0]\n",
    "\n",
    "        input_dim = (input_channels, *input_spatial_dim)\n",
    "        output_dim = (output_channels, *output_spatial_dim)\n",
    "\n",
    "        spatial_scale = output_spatial_dim / input_spatial_dim\n",
    "        if np.any(spatial_scale % 1 != 0):\n",
    "            raise ValueError(\n",
    "                \"scale=(output_dim/input_dim) must be an integer \"\n",
    "                f\"input_dim: {input_dim}, output_dim: {output_dim}, scale: {spatial_scale}\"\n",
    "            )\n",
    "\n",
    "        step_scale = spatial_scale ** (1 / num_layers)\n",
    "        if np.any(step_scale % 1 != 0):\n",
    "            raise ValueError(\n",
    "                \"The scale=(output_dim/input_dim) must be a power of the stride number: scale = stride^num_layers. \"\n",
    "                f\"Scale: {spatial_scale}, num_layers: {num_layers}, stride: {step_scale}\"\n",
    "            )\n",
    "        step_scale = step_scale.astype(np.int32)\n",
    "\n",
    "        if out_channels_per_layer:\n",
    "            if len(out_channels_per_layer) != num_layers:\n",
    "                raise ValueError(\n",
    "                    \"out_channels_per_layer must be equal to the number of layers. \"\n",
    "                    f\"num_layers: {num_layers}, channels_per_layer: {out_channels_per_layer}\"\n",
    "                )\n",
    "            if out_channels_per_layer[-1] != output_channels:\n",
    "                raise ValueError(\n",
    "                    \"The number of channels in the last layer must be equal to the number of output channels. \"\n",
    "                    f\"output_channels: {output_channels}, channels_per_layer[-1]: {out_channels_per_layer[-1]}\"\n",
    "                )\n",
    "        else:\n",
    "            channel_diff = output_channels - input_channels\n",
    "            if channel_diff >= 0:\n",
    "                raise ValueError(\n",
    "                    \"The number of input channels must be greater than the number of output channels. \"\n",
    "                    f\"input_channels: {input_channels}, output_channels: {output_channels}\"\n",
    "                )\n",
    "            step_channel_diff = channel_diff // num_layers\n",
    "            out_channels_per_layer = [\n",
    "                (input_channels + i * step_channel_diff) if i < num_layers else output_channels\n",
    "                for i in range(1, num_layers + 1)\n",
    "            ]\n",
    "\n",
    "        input_dims: list[tuple[int, int, int]] = [input_dim]\n",
    "        output_dims: list[tuple[int, int, int]] = []\n",
    "        for i in range(num_layers):\n",
    "            inp = input_dims[i]\n",
    "            output_dims.append(\n",
    "                (\n",
    "                    out_channels_per_layer[i],\n",
    "                    inp[1] * step_scale[0],\n",
    "                    inp[2] * step_scale[1],\n",
    "                )\n",
    "            )\n",
    "            if i < num_layers - 1:\n",
    "                input_dims.append(output_dims[-1])\n",
    "        assert len(input_dims) == len(output_dims)\n",
    "        assert output_dims[-1] == output_dim\n",
    "\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "\n",
    "        self.layers = [pxnn.Linear(in_features=bottleneck_dim, out_features=input_dim[0] * input_dim[1] * input_dim[2])]\n",
    "\n",
    "        for layer_input, layer_output in zip(input_dims, output_dims):\n",
    "            paddings = [\n",
    "                _calculate_padding_and_output_padding(\n",
    "                    input_dim=layer_input[i + 1],\n",
    "                    output_dim=layer_output[i + 1],\n",
    "                    stride=step_scale[i],\n",
    "                    kernel_size=kernel_size[i],\n",
    "                )\n",
    "                for i in range(2)\n",
    "            ]\n",
    "\n",
    "            padding, output_padding = zip(*paddings)\n",
    "\n",
    "            expected_output = tuple(\n",
    "                step_scale[i] * (layer_input[i + 1] - 1) + kernel_size[i] - 2 * padding[i] + output_padding[i]\n",
    "                for i in range(2)\n",
    "            )\n",
    "            assert expected_output == tuple(layer_output[1:])\n",
    "\n",
    "            self.layers.append(\n",
    "                ConvTranspose(\n",
    "                    num_spatial_dims=2,\n",
    "                    in_channels=layer_input[0],\n",
    "                    out_channels=layer_output[0],\n",
    "                    kernel_size=kernel_size,\n",
    "                    stride=(step_scale[0], step_scale[1]),\n",
    "                    padding=padding,\n",
    "                    output_padding=output_padding,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.vodes = [\n",
    "            pxc.Vode(\n",
    "                (bottleneck_dim,),\n",
    "                energy_fn=pxc.zero_energy,\n",
    "                ruleset={pxc.STATUS.INIT: (\"h, u <- u:to_zero\",)},\n",
    "                tforms={\"to_zero\": lambda n, k, v, rkg: jnp.zeros(n.shape.get())},\n",
    "            ),\n",
    "            pxc.Vode(\n",
    "                input_dim,\n",
    "                ruleset={pxc.STATUS.INIT: (\"h, u <- u:to_zero\",), STATUS_FORWARD: (\"h -> u\",)},\n",
    "                tforms={\"to_zero\": lambda n, k, v, rkg: jnp.zeros_like(v)},\n",
    "            ),\n",
    "        ]\n",
    "        for layer_output in output_dims:\n",
    "            self.vodes.append(\n",
    "                pxc.Vode(\n",
    "                    layer_output,\n",
    "                    ruleset={pxc.STATUS.INIT: (\"h, u <- u:to_zero\",), STATUS_FORWARD: (\"h -> u\",)},\n",
    "                    tforms={\"to_zero\": lambda n, k, v, rkg: jnp.zeros_like(v)},\n",
    "                )\n",
    "            )\n",
    "        self.vodes[-1].h.frozen = True\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "\n",
    "    def __call__(self, x, y) -> jax.Array:\n",
    "        # The defined ruleset for the first node is to set the hidden state to zero,\n",
    "        # independent of the input, so we always pass '-1'.\n",
    "        if x is None:\n",
    "            x = self.vodes[0](-1)\n",
    "        \n",
    "        x = self.layers[0](self.act_fn(x))\n",
    "        x = self.vodes[1](x.reshape(self.input_dim))\n",
    "\n",
    "        for i, layer in enumerate(self.layers[1:]):\n",
    "            act_fn = self.act_fn\n",
    "            x = layer(act_fn(x))\n",
    "            if i == (len(self.layers) - 1):\n",
    "                x = self.output_act_fn(x)\n",
    "            x = self.vodes[i + 2](x)\n",
    "\n",
    "        if y is not None:\n",
    "            if self.channel_last.get():\n",
    "                y = y.transpose(2, 0, 1)\n",
    "            self.vodes[-1].set(\"h\", y)\n",
    "\n",
    "        pred = self.vodes[-1].get(\"u\")\n",
    "        if self.channel_last.get():\n",
    "            pred = pred.transpose(1, 2, 0)\n",
    "        return pred\n",
    "\n",
    "    # def generate(self, internal_state: jax.Array | None = None) -> jax.Array:\n",
    "    #     x = internal_state\n",
    "    #     if x is None:\n",
    "    #         x = self.internal_state\n",
    "\n",
    "    #     x = self.act_fn(self.layers[0](x)).reshape((8, 8, 8))\n",
    "    #     for i, layer in enumerate(self.layers[1:]):\n",
    "    #         act_fn = self.act_fn if i < len(self.layers) - 1 else self.output_act_fn\n",
    "    #         x = act_fn(layer(x))\n",
    "\n",
    "    #     if self.channel_last.get():\n",
    "    #         x = x.transpose(1, 2, 0)\n",
    "    #     return x\n",
    "\n",
    "    @property\n",
    "    def internal_state(self) -> jax.Array:\n",
    "        return self.vodes[0].get(\"h\")\n",
    "\n",
    "\n",
    "def _calculate_padding_and_output_padding(\n",
    "    *, input_dim: int, output_dim: int, stride: int, kernel_size: int\n",
    ") -> tuple[int, int]:\n",
    "    \"\"\"\n",
    "    Calculate the padding and output_padding required for a ConvTranspose layer to achieve the desired output dimension.\n",
    "\n",
    "    Parameters:\n",
    "    input_dim (int): The size of the input dimension (height or width).\n",
    "    output_dim (int): The desired size of the output dimension (height or width).\n",
    "    stride (int): The stride of the convolution.\n",
    "    kernel_size (int): The size of the convolution kernel.\n",
    "\n",
    "    Returns:\n",
    "    tuple: The required padding and output_padding to achieve the desired output dimension.\n",
    "    \"\"\"\n",
    "    no_padding_output_dim = (input_dim - 1) * stride + kernel_size\n",
    "\n",
    "    padding = math.ceil(max(no_padding_output_dim - output_dim, 0) / 2)\n",
    "    output_padding = max(output_dim - (no_padding_output_dim - 2 * padding), 0)\n",
    "\n",
    "    assert no_padding_output_dim - 2 * padding + output_padding == output_dim\n",
    "\n",
    "    return padding, output_padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pxf.vmap(pxu.Mask(pxc.VodeParam | pxc.VodeParam.Cache, (None, 0)), in_axes=0, out_axes=0)\n",
    "def forward(x, y, *, model: Model):\n",
    "    return model(x, y)\n",
    "\n",
    "@pxf.vmap(pxu.Mask(pxc.VodeParam | pxc.VodeParam.Cache, (None, 0)), in_axes=0, out_axes=(None, 0), axis_name=\"batch\")\n",
    "def energy(x, *, model: Model):\n",
    "    y_ = model(x, None)\n",
    "    return jax.lax.pmean(model.energy().sum(), \"batch\"), y_\n",
    "\n",
    "# @pxf.vmap(pxu.Mask(pxc.VodeParam | pxc.VodeParam.Cache, (None, 0)), in_axes=0, out_axes=0)\n",
    "# def forward(example: jax.Array | None = None, *, model: PCDeconvDecoder) -> jax.Array:\n",
    "#     return model(example=example)\n",
    "\n",
    "\n",
    "# @pxf.vmap(pxu.Mask(pxc.VodeParam | pxc.VodeParam.Cache, (None, 0)), in_axes=0, out_axes=0)\n",
    "# def generate(internal_state: jax.Array, *, model: PCDeconvDecoder) -> jax.Array:\n",
    "#     return model.generate(internal_state=internal_state)\n",
    "\n",
    "\n",
    "# @pxf.vmap(pxu.Mask(pxc.VodeParam | pxc.VodeParam.Cache, (None, 0)), in_axes=0, out_axes=(None, 0), axis_name=\"batch\")\n",
    "# def energy(example: jax.Array, *, model: PCDeconvDecoder) -> jax.Array:\n",
    "#     y_ = model(example=example)\n",
    "#     return jax.lax.pmean(model.energy().sum(), \"batch\"), y_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pxf.jit(static_argnums=0)\n",
    "def train_on_batch(\n",
    "    T: int,\n",
    "    x: jax.Array,\n",
    "    y: jax.Array,\n",
    "    *,\n",
    "    model: Model,\n",
    "    optim_w: pxu.Optim,\n",
    "    optim_h: pxu.Optim\n",
    "):\n",
    "    def h_step(i, x, *, model, optim_h):\n",
    "        with pxu.step(model, clear_params=pxc.VodeParam.Cache):\n",
    "            (e, y_), g = pxf.value_and_grad(\n",
    "                pxu.Mask(pxu.m(pxc.VodeParam).has_not(frozen=True), [False, True]),\n",
    "                has_aux=True\n",
    "            )(energy)(x, model=model)\n",
    "        optim_h.step(model, g[\"model\"], True)\n",
    "        return x, None\n",
    "\n",
    "    print(\"Training!\")\n",
    "    model.train()\n",
    "    \n",
    "    # Init step\n",
    "    with pxu.step(model, pxc.STATUS.INIT, clear_params=pxc.VodeParam.Cache):\n",
    "        forward(x, y, model=model)\n",
    "    \n",
    "    # Inference steps\n",
    "    pxf.scan(h_step, xs=jax.numpy.arange(T))(x, model=model, optim_h=optim_h)\n",
    "\n",
    "    # Learning step\n",
    "    with pxu.step(model, clear_params=pxc.VodeParam.Cache):\n",
    "        (e, y_), g = pxf.value_and_grad(pxu.Mask(pxnn.LayerParam, [False, True]), has_aux=True)(energy)(x, model=model)\n",
    "    optim_w.step(model, g[\"model\"])\n",
    "\n",
    "\n",
    "def train(dl, T, *, model: Model, optim_w: pxu.Optim, optim_h: pxu.Optim):\n",
    "    model.vodes[-1].h.frozen = True\n",
    "    for x, y in tqdm(dl):\n",
    "        train_on_batch(T, x, y, model=model, optim_w=optim_w, optim_h=optim_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "@pxf.jit(static_argnums=0)\n",
    "def eval_on_batch(\n",
    "    T: int,\n",
    "    x: jax.Array, \n",
    "    *, \n",
    "    model: Model,\n",
    "    optim_h: pxu.Optim\n",
    "    ):\n",
    "    def h_step(i, x, *, model, optim_h):\n",
    "        with pxu.step(model, clear_params=pxc.VodeParam.Cache):\n",
    "            (e, y_), g = pxf.value_and_grad(\n",
    "                pxu.Mask(pxu.m(pxc.VodeParam).has_not(frozen=True), [False, True]),\n",
    "                has_aux=True\n",
    "            )(energy)(x, model=model)\n",
    "        optim_h.step(model, g[\"model\"], True)\n",
    "        return x, None\n",
    "\n",
    "    print(\"Evaluation!\")  \n",
    "    model.train()\n",
    "\n",
    "    if model.vodes[-1].h.frozen:\n",
    "        print(\"vode[-1] should not be frozen! set frozen=False before calling eval function.\")\n",
    "\n",
    "    # Init step\n",
    "    with pxu.step(model, pxc.STATUS.INIT, clear_params=pxc.VodeParam.Cache):\n",
    "        forward(x, None, model=model)\n",
    "    \n",
    "    # Inference steps\n",
    "    x = pxf.scan(h_step, xs=jax.numpy.arange(T))(x, model=model, optim_h=optim_h)\n",
    "\n",
    "\n",
    "def gen_imgs(dl, T, *, model: Model, optim_h: pxu.Optim):\n",
    "    model.vodes[-1].h.frozen = False\n",
    "    ys_ = []\n",
    "    es = []\n",
    "    for x, y in dl:\n",
    "        eval_on_batch(T, x, model=model, optim_h=optim_h)\n",
    "        u = forward(x, None, model=model)\n",
    "        e = model.energy()\n",
    "        ys_.append(u)\n",
    "        es.append(e)\n",
    "    return np.concatenate(ys_, axis=0), e\n",
    "\n",
    "def tmp_save_imgs(imgs):\n",
    "    tf = tempfile.NamedTemporaryFile()\n",
    "    new_folder = False\n",
    "    while not new_folder:\n",
    "        try:\n",
    "            new_folder=True\n",
    "            os.makedirs(\"./data\"+tf.name+\"_\")\n",
    "        except OSError:\n",
    "            print(\"ERROR\")\n",
    "            tf = tempfile.NamedTemporaryFile()\n",
    "            new_folder=False\n",
    "    for img_idx in range(len(imgs)):\n",
    "        save_image(imgs[img_idx], \"./data\"+tf.name+\"_\"+\"/\"+str(img_idx)+\".png\")\n",
    "    return \"./data\"+tf.name+\"_\"\n",
    "\n",
    "\n",
    "def make_compressed_MNIST_files(test_dataset, data_folder):\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "    # save test images\n",
    "    test_img_folder = data_folder + \"/mnist_test\"\n",
    "    data, label = list(test_loader)[0]\n",
    "    images = data.view(-1,28,28)\n",
    "    images = images/2 + 0.5     # remove normalisation\n",
    "    os.makedirs(test_img_folder, exist_ok=True)\n",
    "    for img_idx in tqdm(range(len(images))):\n",
    "        save_image(images[img_idx], test_img_folder+\"/\"+str(img_idx)+\".png\")\n",
    "    # get and save summary statistics of test images\n",
    "    compressed_filename = test_img_folder + \".npz\"    \n",
    "    save_stats_mnist(test_img_folder, compressed_filename)    \n",
    "\n",
    "\n",
    "from scipy.ndimage import zoom\n",
    "# Assuming `images` is your numpy array of shape (batch, 32, 32)\n",
    "def resize_images_scipy(images, new_size=(28, 28)):\n",
    "    batch_size = images.shape[0]\n",
    "    resized_images = np.zeros((batch_size, *new_size))\n",
    "    for i in range(batch_size):\n",
    "        resized_images[i] = zoom(images[i], (new_size[0] / images.shape[1], new_size[1] / images.shape[2]))\n",
    "    return resized_images\n",
    "\n",
    "# MCPC evaluation loop for 1D data\n",
    "def eval(dl, dataset, T, *, model: Model, optim_h: pxu.Optim):\n",
    "    model.vodes[-1].h.frozen = False\n",
    "\n",
    "    # check if summary statistics of test dataset used for FID exist\n",
    "    data_folder = './data'\n",
    "    if not os.path.exists(data_folder + \"/mnist_test.npz\") :\n",
    "        print(data_folder + \"/mnist_test\" + \"does not exist\")\n",
    "        print(\"Creating compressed MNIST files for faster FID measure ...\")\n",
    "        make_compressed_MNIST_files(dataset, data_folder=data_folder)\n",
    " \n",
    "    # generate images from model\n",
    "    imgs, e = gen_imgs(dl, T, model=model, optim_h=optim_h)\n",
    "    imgs = imgs/2 + 0.5     # from -1 -> 1 to 0 -> 1\n",
    "    imgs = np.clip(imgs, 0, 1).squeeze()\n",
    "    imgs = resize_images_scipy(imgs)\n",
    "\n",
    "    # # save images\n",
    "    img_folder = tmp_save_imgs(torch.tensor(imgs).reshape(-1,28,28))\n",
    "    # get inceptions score\n",
    "    is_mean, is_std = get_mnist_inception_score(img_folder)\n",
    "\n",
    "    # get mnist fid\n",
    "    fid = fid_mnist(data_folder + \"/mnist_test.npz\", img_folder, device=torch.device(\"cpu\"), num_workers=0, verbose=False)\n",
    "\n",
    "    shutil.rmtree(img_folder)\n",
    "\n",
    "    return is_mean, fid, imgs, e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optax\n",
    "\n",
    "batch_size = 10\n",
    "latent_dim = 128\n",
    "img_dim = (1,32,32)\n",
    "model = Model(\n",
    "    num_layers=2,\n",
    "    input_dim=(8,8,8),\n",
    "    output_dim=img_dim,\n",
    "    kernel_size=5,\n",
    "    bottleneck_dim=latent_dim,\n",
    "    act_fn=jax.nn.tanh,\n",
    "    output_act_fn=lambda x: x,\n",
    "    channel_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define noisy sgd optimiser for MCPC\n",
    "def sgdld(\n",
    "    learning_rate: base.ScalarOrSchedule,\n",
    "    momentum: Optional[float] = None,\n",
    "    h_var: float = 1.0,\n",
    "    gamma: float = 0.,\n",
    "    nesterov: bool = False,\n",
    "    accumulator_dtype: Optional[Any] = None,\n",
    "    seed: int = 0\n",
    ") -> base.GradientTransformation:\n",
    "  eta = 2*h_var*(1-momentum)/learning_rate if momentum is not None else 2*h_var/learning_rate\n",
    "  return combine.chain(\n",
    "      transform.add_noise(eta, gamma, seed),\n",
    "      (transform.trace(decay=momentum, nesterov=nesterov,\n",
    "                       accumulator_dtype=accumulator_dtype)\n",
    "       if momentum is not None else base.identity()),\n",
    "      transform.scale_by_learning_rate(learning_rate)\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Tuple arity mismatch: 3 != 2; tuple: (None, Array([[[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       ...,\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), {'__RKG': (RandomKeyGenerator):\n  .key: RKGState([2], uint32), 'model': (Model):\n  .layers[0].nn.weight: LayerParam([512,128], float32)\n  .layers[0].nn.bias: LayerParam([512], float32)\n  .layers[1].nn.weight: LayerParam([4,8,5,5], float32)\n  .layers[1].nn.bias: LayerParam([4,1,1], float32)\n  .layers[2].nn.weight: LayerParam([1,4,5,5], float32)\n  .layers[2].nn.bias: LayerParam([1,1,1], float32)\n  .vodes[0].h: VodeParam(None)\n  .vodes[0].cache: Cache(params={})\n  .vodes[1].h: VodeParam(None)\n  .vodes[1].cache: Cache(params={})\n  .vodes[2].h: VodeParam(None)\n  .vodes[2].cache: Cache(params={})\n  .vodes[3].h: VodeParam(None)\n  .vodes[3].cache: Cache(params={})\n  .input_dim[0]: 8\n  .input_dim[1]: 8\n  .input_dim[2]: 8}).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m lr_p \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.007\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pxu\u001b[38;5;241m.\u001b[39mstep(model, pxc\u001b[38;5;241m.\u001b[39mSTATUS\u001b[38;5;241m.\u001b[39mINIT, clear_params\u001b[38;5;241m=\u001b[39mpxc\u001b[38;5;241m.\u001b[39mVodeParam\u001b[38;5;241m.\u001b[39mCache):\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mimg_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:175\u001b[0m, in \u001b[0;36m_BaseTransform.__call__\u001b[0;34m(self, _is_root, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_root \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m tree_ref(kwargs)\n\u001b[0;32m--> 175\u001b[0m _r, _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_t\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# This is the key part: the updated values are injected back into the original parameters in 'kwargs'. 'kwargs'\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# is still the original structure as it hasn't undergone any transformation (which happens only inside '_t').\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# The update values are obtained by calling 'extract', which is done automatically by the wrapped 'fn'.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# If 'tree_extract' is called before returning '_kwargs', a list of value was returned, so we tell 'tree_inject'\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# to handle it correctly.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:364\u001b[0m, in \u001b[0;36mVmap._t\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    359\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m param\u001b[38;5;241m.\u001b[39mshape[mask]\n\u001b[1;32m    361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    363\u001b[0m _vaxis_dim \u001b[38;5;241m=\u001b[39m jtu\u001b[38;5;241m.\u001b[39mtree_leaves(\n\u001b[0;32m--> 364\u001b[0m     \u001b[43mjtu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtree_map\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_extract_vaxes_dim\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_in_axes_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    365\u001b[0m )[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    367\u001b[0m \u001b[38;5;66;03m# Split the __RKG key over the vmap axis (and set the mask accordingly)\u001b[39;00m\n\u001b[1;32m    368\u001b[0m _in_axes_mask[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__RKG\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/envs/pcax/lib/python3.10/site-packages/jax/_src/tree_util.py:319\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(f, tree, is_leaf, *rest)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m  - :func:`jax.tree.reduce`\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    318\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 319\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treedef\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/envs/pcax/lib/python3.10/site-packages/jax/_src/tree_util.py:319\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maps a multi-input function over pytree args to produce a new pytree.\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \n\u001b[1;32m    284\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;124;03m  - :func:`jax.tree.reduce`\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    318\u001b[0m leaves, treedef \u001b[38;5;241m=\u001b[39m tree_flatten(tree, is_leaf)\n\u001b[0;32m--> 319\u001b[0m all_leaves \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [\u001b[43mtreedef\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten_up_to\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rest]\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m treedef\u001b[38;5;241m.\u001b[39munflatten(f(\u001b[38;5;241m*\u001b[39mxs) \u001b[38;5;28;01mfor\u001b[39;00m xs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mall_leaves))\n",
      "\u001b[0;31mValueError\u001b[0m: Tuple arity mismatch: 3 != 2; tuple: (None, Array([[[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       ...,\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]],\n\n\n       [[[0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         ...,\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.],\n         [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32), {'__RKG': (RandomKeyGenerator):\n  .key: RKGState([2], uint32), 'model': (Model):\n  .layers[0].nn.weight: LayerParam([512,128], float32)\n  .layers[0].nn.bias: LayerParam([512], float32)\n  .layers[1].nn.weight: LayerParam([4,8,5,5], float32)\n  .layers[1].nn.bias: LayerParam([4,1,1], float32)\n  .layers[2].nn.weight: LayerParam([1,4,5,5], float32)\n  .layers[2].nn.bias: LayerParam([1,1,1], float32)\n  .vodes[0].h: VodeParam(None)\n  .vodes[0].cache: Cache(params={})\n  .vodes[1].h: VodeParam(None)\n  .vodes[1].cache: Cache(params={})\n  .vodes[2].h: VodeParam(None)\n  .vodes[2].cache: Cache(params={})\n  .vodes[3].h: VodeParam(None)\n  .vodes[3].cache: Cache(params={})\n  .input_dim[0]: 8\n  .input_dim[1]: 8\n  .input_dim[2]: 8})."
     ]
    }
   ],
   "source": [
    "h_optimiser_fn = sgdld\n",
    "lr = 0.03\n",
    "momentum = 0.9\n",
    "h_var = 1.0\n",
    "gamma = 0.0\n",
    "lr_p = 0.007\n",
    "\n",
    "with pxu.step(model, pxc.STATUS.INIT, clear_params=pxc.VodeParam.Cache):\n",
    "    forward(None, jax.numpy.zeros((batch_size, *img_dim)), model=model)\n",
    "    # optim_h = pxu.Optim(h_optimiser_fn(lr, momentum, h_var, gamma), pxu.Mask(pxu.m(pxc.VodeParam).has_not(frozen=True))(model))\n",
    "    # optim_w = pxu.Optim(optax.adam(lr_p), pxu.Mask(pxnn.LayerParam)(model))\n",
    "    # # make optimiser that also optimises the activity of the model layer[-1]\n",
    "    # model.vodes[-1].h.frozen = False\n",
    "    # forward(jax.numpy.zeros((batch_size, latent_dim)), None, model=model)\n",
    "    # optim_h_eval = pxu.Optim(h_optimiser_fn(lr, momentum, h_var, gamma), pxu.Mask(pxu.m(pxc.VodeParam))(model))\n",
    "    # model.vodes[-1].h.frozen = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation to scale pixels to the range [-1, 1], resize and add channel\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),                # Resize the image to 32x32 pixels\n",
    "    transforms.ToTensor(),                      # Convert the image to a PyTorch tensor\n",
    "    transforms.Normalize((0.5,), (0.5,)),       # Normalize the tensor to the range [-1, 1]\n",
    "    transforms.Lambda(lambda x: x.unsqueeze(0) if x.dim() == 2 else x) # Ensure the tensor shape is [1 x 32 x 32]\n",
    "])\n",
    "\n",
    "# Load the MNIST training dataset\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# Load the MNIST test dataset\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data for unsupervised training\n",
    "train_dl = DataLoader(train_dataset, batch_size=train_dataset.__len__(), shuffle=True)\n",
    "\n",
    "data, label = list(train_dl)[0]\n",
    "nm_elements = len(data)\n",
    "X = np.zeros((batch_size * (nm_elements // batch_size), latent_dim))\n",
    "y = data.numpy()[:batch_size * (nm_elements // batch_size)]\n",
    "\n",
    "nm_elements_test =  1024\n",
    "X_test = np.zeros((batch_size * (nm_elements_test // batch_size), latent_dim))\n",
    "y_test = np.zeros((batch_size * (nm_elements_test // batch_size), *img_dim)) # is not used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = list(zip(X.reshape(-1, batch_size, latent_dim), y.reshape(-1, batch_size, *img_dim)))\n",
    "test_dl = tuple(zip(X_test.reshape(-1, batch_size, latent_dim), y_test.reshape(-1, batch_size, *img_dim)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inception score -> higher is better\n",
    "\n",
    "FID -> lower is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                           | 0/6000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training!\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Shapes must be 1D sequences of concrete values of integer type, got (Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=1/0)>, Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>).\nIf using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions.\nThe error occurred while tracing the function _wrap_fn at /data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:252 for jit. This concrete value was not available in Python because it depends on the value of the argument kwargs['model'].input_dim[0].\nThe error occurred while tracing the function _wrap_fn at /data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:252 for jit. This concrete value was not available in Python because it depends on the value of the argument kwargs['model'].input_dim[1].\nThe error occurred while tracing the function _wrap_fn at /data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:252 for jit. This concrete value was not available in Python because it depends on the value of the argument kwargs['model'].input_dim[2].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(nm_epochs):\n\u001b[1;32m      8\u001b[0m     random\u001b[38;5;241m.\u001b[39mshuffle(train_dl)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_h\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim_h\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m e \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m9\u001b[39m:\n\u001b[1;32m     11\u001b[0m         is_, fid, imgs, energies \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m(test_dl, test_dataset, T_eval, model\u001b[38;5;241m=\u001b[39mmodel, optim_h\u001b[38;5;241m=\u001b[39moptim_h_eval)\n",
      "Cell \u001b[0;32mIn[5], line 39\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(dl, T, model, optim_w, optim_h)\u001b[0m\n\u001b[1;32m     37\u001b[0m model\u001b[38;5;241m.\u001b[39mvodes[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mh\u001b[38;5;241m.\u001b[39mfrozen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m tqdm(dl):\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_w\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim_w\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptim_h\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim_h\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:175\u001b[0m, in \u001b[0;36m_BaseTransform.__call__\u001b[0;34m(self, _is_root, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_root \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m tree_ref(kwargs)\n\u001b[0;32m--> 175\u001b[0m _r, _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_t\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# This is the key part: the updated values are injected back into the original parameters in 'kwargs'. 'kwargs'\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# is still the original structure as it hasn't undergone any transformation (which happens only inside '_t').\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# The update values are obtained by calling 'extract', which is done automatically by the wrapped 'fn'.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# If 'tree_extract' is called before returning '_kwargs', a list of value was returned, so we tell 'tree_inject'\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# to handle it correctly.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:260\u001b[0m, in \u001b[0;36mJit._t\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_t\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 260\u001b[0m     _r, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrap_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _r, kwargs\n",
      "    \u001b[0;31m[... skipping hidden 11 frame]\u001b[0m\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:253\u001b[0m, in \u001b[0;36mJit.__init__.<locals>._wrap_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 253\u001b[0m     _r, _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _r, tree_extract(_kwargs, is_pytree\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:147\u001b[0m, in \u001b[0;36m_BaseTransform.__init__.<locals>._map_fn.<locals>._wrap_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m _fn_kwargs \u001b[38;5;241m=\u001b[39m tree_unref(kwargs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _fn_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__RKG\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 147\u001b[0m _r \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_fn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m RKG\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m _old_key\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _r, kwargs\n",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m, in \u001b[0;36mtrain_on_batch\u001b[0;34m(T, x, y, model, optim_w, optim_h)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Init step\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m pxu\u001b[38;5;241m.\u001b[39mstep(model, pxc\u001b[38;5;241m.\u001b[39mSTATUS\u001b[38;5;241m.\u001b[39mINIT, clear_params\u001b[38;5;241m=\u001b[39mpxc\u001b[38;5;241m.\u001b[39mVodeParam\u001b[38;5;241m.\u001b[39mCache):\n\u001b[0;32m---> 25\u001b[0m     \u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Inference steps\u001b[39;00m\n\u001b[1;32m     28\u001b[0m pxf\u001b[38;5;241m.\u001b[39mscan(h_step, xs\u001b[38;5;241m=\u001b[39mjax\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39marange(T))(x, model\u001b[38;5;241m=\u001b[39mmodel, optim_h\u001b[38;5;241m=\u001b[39moptim_h)\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:175\u001b[0m, in \u001b[0;36m_BaseTransform.__call__\u001b[0;34m(self, _is_root, *args, **kwargs)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _is_root \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    174\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m tree_ref(kwargs)\n\u001b[0;32m--> 175\u001b[0m _r, _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_t\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;66;03m# This is the key part: the updated values are injected back into the original parameters in 'kwargs'. 'kwargs'\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# is still the original structure as it hasn't undergone any transformation (which happens only inside '_t').\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;66;03m# The update values are obtained by calling 'extract', which is done automatically by the wrapped 'fn'.\u001b[39;00m\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# If 'tree_extract' is called before returning '_kwargs', a list of value was returned, so we tell 'tree_inject'\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# to handle it correctly.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(kwargs, \u001b[38;5;28mdict\u001b[39m):\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:377\u001b[0m, in \u001b[0;36mVmap._t\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    373\u001b[0m     _r, _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfn(\u001b[38;5;241m*\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _r, _kwargs\n\u001b[0;32m--> 377\u001b[0m _r, kwargs \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvmap\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_wrap_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43min_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_in_axes_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt_kwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mout_axes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_kwargs_mask\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;66;03m# Merge back the key value to remove the vmap axis before returning it;\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;66;03m# it will automatically be injected back into the global RKG (being it a kwarg)\u001b[39;00m\n\u001b[1;32m    388\u001b[0m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__RKG\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mkey\u001b[38;5;241m.\u001b[39mset(kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__RKG\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mkey[\u001b[38;5;241m0\u001b[39m])\n",
      "    \u001b[0;31m[... skipping hidden 3 frame]\u001b[0m\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:373\u001b[0m, in \u001b[0;36mVmap._t.<locals>._wrap_fn\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):\n\u001b[1;32m    372\u001b[0m     \u001b[38;5;241m*\u001b[39m_args, _kwargs \u001b[38;5;241m=\u001b[39m args\n\u001b[0;32m--> 373\u001b[0m     _r, _kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _r, _kwargs\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:147\u001b[0m, in \u001b[0;36m_BaseTransform.__init__.<locals>._map_fn.<locals>._wrap_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m _fn_kwargs \u001b[38;5;241m=\u001b[39m tree_unref(kwargs)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _fn_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__RKG\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m--> 147\u001b[0m _r \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_fn_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    149\u001b[0m RKG\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;241m=\u001b[39m _old_key\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _r, kwargs\n",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m, in \u001b[0;36mforward\u001b[0;34m(x, y, model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;129m@pxf\u001b[39m\u001b[38;5;241m.\u001b[39mvmap(pxu\u001b[38;5;241m.\u001b[39mMask(pxc\u001b[38;5;241m.\u001b[39mVodeParam \u001b[38;5;241m|\u001b[39m pxc\u001b[38;5;241m.\u001b[39mVodeParam\u001b[38;5;241m.\u001b[39mCache, (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m)), in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), out_axes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(x, y, \u001b[38;5;241m*\u001b[39m, model: Model):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 163\u001b[0m, in \u001b[0;36mModel.__call__\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    160\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvodes[\u001b[38;5;241m0\u001b[39m](\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    162\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m0\u001b[39m](\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn(x))\n\u001b[0;32m--> 163\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvodes[\u001b[38;5;241m1\u001b[39m](\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_dim\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers[\u001b[38;5;241m1\u001b[39m:]):\n\u001b[1;32m    166\u001b[0m     act_fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact_fn\n",
      "    \u001b[0;31m[... skipping hidden 2 frame]\u001b[0m\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/envs/pcax/lib/python3.10/site-packages/jax/_src/numpy/array_methods.py:117\u001b[0m, in \u001b[0;36m_compute_newshape\u001b[0;34m(a, newshape)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m   newshape \u001b[38;5;241m=\u001b[39m [newshape]\n\u001b[0;32m--> 117\u001b[0m newshape \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanonicalize_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewshape\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    118\u001b[0m neg1s \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i, d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(newshape) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(d) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mint\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m d \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    119\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(neg1s) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/data/ndcn-computational-neuroscience/pemb6612/envs/pcax/lib/python3.10/site-packages/jax/_src/core.py:1647\u001b[0m, in \u001b[0;36mcanonicalize_shape\u001b[0;34m(shape, context)\u001b[0m\n\u001b[1;32m   1645\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   1646\u001b[0m   \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m-> 1647\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m _invalid_shape_error(shape, context)\n",
      "\u001b[0;31mTypeError\u001b[0m: Shapes must be 1D sequences of concrete values of integer type, got (Traced<ShapedArray(int32[], weak_type=True)>with<DynamicJaxprTrace(level=1/0)>, Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>, Traced<ShapedArray(int32[])>with<DynamicJaxprTrace(level=1/0)>).\nIf using `jit`, try using `static_argnums` or applying `jit` to smaller subfunctions.\nThe error occurred while tracing the function _wrap_fn at /data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:252 for jit. This concrete value was not available in Python because it depends on the value of the argument kwargs['model'].input_dim[0].\nThe error occurred while tracing the function _wrap_fn at /data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:252 for jit. This concrete value was not available in Python because it depends on the value of the argument kwargs['model'].input_dim[1].\nThe error occurred while tracing the function _wrap_fn at /data/ndcn-computational-neuroscience/pemb6612/pcax/pcax/functional/_transform.py:252 for jit. This concrete value was not available in Python because it depends on the value of the argument kwargs['model'].input_dim[2]."
     ]
    }
   ],
   "source": [
    "nm_epochs = 40\n",
    "\n",
    "T = 250\n",
    "T_eval = 10000\n",
    "# is_, fid, imgs, energies = eval(test_dl, test_dataset, T_eval, model=model, optim_h=optim_h_eval)\n",
    "# print(f\"Epoch {0}/{nm_epochs} - Inception score: {is_ :.2f}, FID score: {fid :.2f}\")\n",
    "for e in range(nm_epochs):\n",
    "    random.shuffle(train_dl)\n",
    "    train(train_dl, T=T, model=model, optim_w=optim_w, optim_h=optim_h)\n",
    "    if e % 10 == 9:\n",
    "        is_, fid, imgs, energies = eval(test_dl, test_dataset, T_eval, model=model, optim_h=optim_h_eval)\n",
    "        print(f\"Epoch {e}/{nm_epochs} - Inception score: {is_ :.2f}, FID score: {fid :.2f}\")\n",
    "\n",
    "is_, fid, imgs, energies = eval(test_dl, test_dataset, T_eval, model=model, optim_h=optim_h_eval)\n",
    "print(f\"Epoch {e}/{nm_epochs} - Inception score: {is_ :.2f}, FID score: {fid :.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
