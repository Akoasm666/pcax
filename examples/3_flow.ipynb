{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial #3: Flow in JAX and pcax.\n",
    "\n",
    "Since JAX transformations are compiled, we cannot use python control flow, but we must rely on JAX primitives and follow their constraints.\n",
    "Similarly to other transformations, pcax offers custom wraps of JAX flow transformations that automatically track changes to their kwargs.\n",
    "\n",
    "In particular, only static values can be used with python static flow, so it's totally fine to have flags within a model to change the overall computation.\n",
    "Remember that everytime a static value is updated, a recompilation is triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-14 10:21:48.814215: W external/xla/xla/service/gpu/nvptx_compiler.cc:760] The NVIDIA driver's CUDA version is 12.0 which is older than the ptxas CUDA version (12.4.131). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n"
     ]
    }
   ],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "\n",
    "import pcax as px\n",
    "import pcax.functional as pxf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of static flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f is being compiled...\n",
      "x: 2.0\n",
      "x: 3.0\n",
      "f is being compiled...\n",
      "x: 2.0\n",
      "x: 1.0\n"
     ]
    }
   ],
   "source": [
    "model = {\n",
    "    'x': px.Param(1.0),\n",
    "    'c': px.static(True)\n",
    "}\n",
    "\n",
    "@pxf.jit()\n",
    "def f(*, model):\n",
    "    print(\"f is being compiled...\")\n",
    "    \n",
    "    if model['c'].get():\n",
    "        model['x'] += 1.0\n",
    "    else:\n",
    "        model['x'] -= 1.0\n",
    "\n",
    "f(model=model)\n",
    "print('x:', model['x'].get())\n",
    "f(model=model)\n",
    "print('x:', model['x'].get())\n",
    "\n",
    "model['c'].set(False)\n",
    "f(model=model)\n",
    "print('x:', model['x'].get())\n",
    "f(model=model)\n",
    "print('x:', model['x'].get())\n",
    "\n",
    "# if 'c' is not set as static value it will not work. Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choice_a(x: jax.Array, *, p: px.Param):\n",
    "    p -= x  # NOTE: remember `p = p - x` is wrong, since `p` is a param and `p - x` is casted to a jax.Array\n",
    "\n",
    "def choice_b(x: jax.Array, *, p: px.Param):\n",
    "    p.set(p * x)\n",
    "\n",
    "@pxf.jit()\n",
    "def f(x: jax.Array, c: bool, *, p: px.Param):\n",
    "    # NOTE: c is automatically casted to a dynamic value by JAX, so within the function, it is a 0-dim jax.Array\n",
    "    pxf.cond(choice_a, choice_b)(c, x, p=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = px.Param(jnp.array([1.0]))\n",
    "x = jnp.array([-2.0])\n",
    "\n",
    "f(x, True, p = param)  # 1.0 - (-2.0) = 3.0\n",
    "f(x, False, p = param)  # 3.0 * (-2.0) = -6.0\n",
    "\n",
    "assert param.get().item() == -6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply the operation multiple times, we can use `scan`. Note that `scan` requires a static shape (or a fixed length) to know the number of repetitions at compilation time.\n",
    "Furthermore note that for better clarity, we opted to move the scan index 'i' before the arguments list in the transformed function (i.e., the signature is `f(i, *args, **kwargs)` instead of the lax `f(carry, i)`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "@pxf.jit()\n",
    "def fix_many_f(x: jax.Array, c: jax.Array, *, p: px.Param):\n",
    "    def f(i, x, *, p):\n",
    "        pxf.cond(choice_a, choice_b)(i, x, p=p)\n",
    "        \n",
    "        # NOTE: `jax.lax.scan` requires to always return a tuple made by:\n",
    "        # - the updated tuple of args except the given index 'i' (so we return 'x', '(x,)' would also be fine)\n",
    "        # - 'y', that is the intermediate result we wish to save for the loop. We can simply return 'None'.\n",
    "        return x, None\n",
    "    pxf.scan(f, c)(x, p=p)\n",
    "\n",
    "param = px.Param(jnp.array([1.0]))\n",
    "x = jnp.array([-2.0])\n",
    "\n",
    "c = jnp.array([False, False, True, False, True, True, False, True])\n",
    "d = jnp.arange(10)\n",
    "print(d)\n",
    "fix_many_f(x, c, p=param)\n",
    "\n",
    "assert param.get().item() == 18.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to run something until some arbitrary condition, we can use `while_loop`. Note we put a counter so there is no risk to run the loop indefinitely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-6.] steps: 2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "@pxf.jit()\n",
    "def var_many_f(x: jax.Array, *, p: px.Param):\n",
    "    def f(x, count, *, p):\n",
    "        c = jax.random.bernoulli(px.RKG())\n",
    "        pxf.cond(choice_a, choice_b)(c, x, p=p)\n",
    "        \n",
    "        # NOTE: `jax.lax.while_loop` requires to always return the updated tuple of args.\n",
    "        return x, count + 1\n",
    "    def loop_cond(x, count, *, p):\n",
    "        # NOTE: 'loop_cond' has access to both args and kwargs.\n",
    "        # We use `.all` to convert the 1-dim to a 0-dim array that can be evaluated as `bool`.\n",
    "        return jnp.all(jnp.logical_and(p > 0.0, count < 3))\n",
    "    return pxf.while_loop(f, loop_cond)(x, 0, p=p)\n",
    "\n",
    "param = px.Param(jnp.array([1.0]))\n",
    "x = jnp.array([-2.0])\n",
    "\n",
    "_, count = var_many_f(x, p=param)\n",
    "\n",
    "print(param.get(), \"steps:\", count)\n",
    "\n",
    "# Note that each iteration we get 50% chance to go negative. So only around 1/8 of the times we\n",
    "# should get a positive number.\n",
    "values = []\n",
    "for i in range(1024):\n",
    "    param = px.Param(jnp.array([1.0]))\n",
    "    var_many_f(x, p=param)\n",
    "    \n",
    "    values.append(param.get().item() > 0)\n",
    "\n",
    "assert np.allclose(np.mean(values), 1/8, atol=0.05)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
